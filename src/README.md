# Скрипты обработки и анализа данных

Все скрипты проекта организованы по этапам исследования согласно плану в основном README.

---

## Этап 1: Подготовка данных

### `parse_xml_to_csv.py`
**Назначение:** Парсинг XML датасета и конвертация в CSV/Parquet форматы.

**Использование:**
```bash
python src/parse_xml_to_csv.py
```

**Что делает:**
- Парсит `dataset/all.xml`
- Извлекает все поля стихотворений (author, name, text, dates, themes)
- Вычисляет средний год написания (`year`)
- Сохраняет результат в:
  - `dataset/poems.csv` - человекочитаемый формат (24 MB)
  - `dataset/poems.parquet` - оптимизированный формат (13 MB, экономия 45%)
- Выводит статистику по датасету

**Результат:**
- 16,694 стихотворений
- 195 авторов
- Период: 1725-1996
- 77% стихотворений имеют даты

### `example_load_data.py`
**Назначение:** Примеры загрузки и базовой работы с датасетом.

**Использование:**
```bash
python src/example_load_data.py
```

**Что показывает:**
- Как загрузить данные из CSV или Parquet
- Фильтрация по автору и периоду
- Базовая статистика
- Примеры анализа

---

## Этап 2: Формирование словаря архаизмов

### `parse_archaisms.py`
**Назначение:** Парсинг словаря устаревших слов из текстового файла.

**Использование:**
```bash
python src/parse_archaisms.py
```

**Что делает:**
- Парсит `dataset/устаревшие.txt` (источник: azbyka.ru)
- Извлекает слова, определения и варианты написания
- Сохраняет результат в:
  - `dataset/archaisms.csv` - полный словарь с определениями (124 KB)
  - `dataset/archaisms.parquet` - оптимизированный формат (78 KB)
  - `dataset/archaisms_wordlist.txt` - простой список слов для поиска (17 KB)
- Выводит статистику по словарю

**Результат:**
- 1,123 словарных записи
- 1,188 уникальных слов (с вариантами)
- Распределение по алфавиту

### `example_find_archaisms.py`
**Назначение:** Примеры поиска архаизмов в стихотворениях.

**Использование:**
```bash
python src/example_find_archaisms.py
```

**Что показывает:**
- Как загрузить словарь архаизмов
- Поиск архаизмов в текстах
- Подсчёт процента архаизмов
- Сравнение разных авторов и эпох

---

## Этап 3: Анализ частотности

### `word_frequency_analysis.py`
**Назначение:** Анализ частотности слов по векам с визуализацией облаков слов.

**Использование:**
```bash
python src/word_frequency_analysis.py
```

**Что делает:**
- Разделяет корпус по векам (18, 19, 20)
- Подсчитывает частотность всех слов
- Создаёт облака слов двух типов для каждого века:
  - **Частые слова** - чем чаще, тем крупнее
  - **Редкие слова** - чем реже, тем крупнее (инвертированное)
- Сохраняет визуализации в `results/`

**Результат:**
6 PNG-изображений (по 2 для каждого века):
- `wordcloud_18_century_frequent.png` и `*_rare.png`
- `wordcloud_19_century_frequent.png` и `*_rare.png`
- `wordcloud_20_century_frequent.png` и `*_rare.png`

**Статистика по векам:**
- 18 век: 375 стихотворений, 21,463 уникальных слова
- 19 век: 4,684 стихотворения, 74,171 уникальное слово
- 20 век: 7,798 стихотворений, 124,371 уникальное слово

---

### `add_archaisms_from_manual.py`
**Назначение:** Добавление архаизмов из ручного списка в основной словарь.

**Использование:**
```bash
python src/add_archaisms_from_manual.py
```

**Что делает:**
- Читает `dataset/устаревшие_из_облака.txt` (ручной список)
- Проверяет наличие слов в существующем словаре
- Добавляет новые слова в `archaisms.csv` и `archaisms.parquet`
- Обновляет `archaisms_wordlist.txt`
- Выводит статистику: сколько добавлено, сколько уже было

**Результат (пример):**
- Проверено: 19 слов
- Уже присутствовали: 1
- Добавлено новых: 18
- Словарь увеличился с 1,188 до 1,206 слов

---

### `analyze_archaism_frequency.py`
**Назначение:** Полный анализ частотности архаизмов по десятилетиям с графиками.

**Использование:**
```bash
python src/analyze_archaism_frequency.py
```

**Что делает:**
- Подсчитывает употребления архаизмов по десятилетиям (1720-2000)
- Вычисляет относительную частотность (архаизмов на 1000 слов)
- Анализирует топ-10 авторов по использованию архаизмов
- Строит 3 графика:
  1. Динамика частотности по десятилетиям
  2. Сравнение авторов
  3. Сравнение по векам
- Сохраняет статистические таблицы в CSV

**Результат:**
- 3 PNG-графика в `results/`:
  - `archaism_dynamics_by_decade.png` (400 KB)
  - `archaism_by_author.png` (212 KB)
  - `archaism_by_century.png` (108 KB)
- 2 CSV-таблицы:
  - `archaism_frequency_by_decade.csv`
  - `archaism_frequency_by_author.csv`

**Ключевые находки:**
- Всего архаизмов в корпусе: 14,922
- Средняя частотность: 8.64 на 1000 слов
- Пик использования: 1720s (27.69 на 1000 слов)
- Минимум: 1990s (5.92 на 1000 слов)
- Лидер среди авторов: Михаил Лермонтов (12.81 на 1000 слов)

---

## Этап 4: Сравнительный анализ

### `comparative_analysis.py`
**Назначение:** Сравнительный анализ использования архаизмов с привязкой к литературным течениям.

**Использование:**
```bash
python src/comparative_analysis.py
```

**Что делает:**
- Определяет периоды интенсивной архаизации (выше 75-го перцентиля)
- Анализирует 8 литературных течений (Классицизм, Романтизм, Символизм и др.)
- Классифицирует авторов по течениям
- Вычисляет среднюю частотность архаизмов для каждого течения
- Строит 2 графика:
  1. Сравнение течений по частотности
  2. Временная шкала с выделением течений
- Генерирует подробный аналитический отчёт с выводами

**Результат:**
- 2 PNG-графика в `results/`:
  - `literary_movements_comparison.png` - сравнение течений
  - `timeline_with_movements.png` - временная шкала
- 1 CSV-таблица:
  - `archaism_by_movement.csv` - статистика по течениям
- **Аналитический отчёт:**
  - `ANALYSIS_REPORT.txt` - детальный анализ с выводами

**Ключевые находки:**

**Ранжирование течений по архаизации:**
1. Классицизм (1730-1800): 16.93 на 1000 слов
2. Сентиментализм (1770-1820): 13.17 на 1000 слов
3. Романтизм (1800-1840): 11.68 на 1000 слов
4. Реализм (1840-1890): 8.70 на 1000 слов
5. Символизм (1890-1910): 8.38 на 1000 слов
6. Акмеизм (1910-1920): 7.70 на 1000 слов
7. Футуризм (1910-1930): 7.53 на 1000 слов
8. Советская поэзия (1920-1990): 6.62 на 1000 слов

**Выводы:**
- Классицизм - максимальная архаизация (ориентация на античность)
- Романтизм - высокая архаизация (связь с историей и народностью)
- Советская поэзия - минимальная архаизация (урбанизация языка)
- Разброс между течениями: σ = 3.55 (статистически значимо)
- Снижение архаизации с 18 по 20 век коррелирует со сменой эстетических парадигм

---

## Структура данных

После парсинга датасет имеет следующие колонки:

| Колонка    | Тип    | Описание                                    | Пример                    |
|------------|--------|---------------------------------------------|---------------------------|
| author     | str    | Имя автора                                  | "Александр Пушкин"        |
| name       | str    | Название стихотворения                      | "Я помню чудное мгновенье"|
| text       | str    | Полный текст стихотворения                  | "Я помню чудное..."       |
| date_from  | str    | Год начала написания (может быть пустым)    | "1825"                    |
| date_to    | str    | Год окончания написания (может быть пустым) | "1825"                    |
| themes     | str    | Темы через запятую (может быть пустым)      | "О любви, Романтизм"      |
| year       | float  | Средний год написания для анализа           | 1825.0                    |

---

## Быстрый старт

### 1. Активация виртуального окружения
```bash
source venv/bin/activate
```

### 2. Загрузка данных в Python
```python
import pandas as pd

# Быстрая загрузка (рекомендуется)
df = pd.read_parquet('dataset/poems.parquet')

# Или из CSV
df = pd.read_csv('dataset/poems.csv')
```

### 3. Базовый анализ
```python
# Фильтрация по автору
pushkin = df[df['author'] == 'Александр Пушкин']

# Фильтрация по периоду
golden_age = df[(df['year'] >= 1820) & (df['year'] < 1840)]

# Группировка по десятилетиям
df['decade'] = (df['year'] // 10) * 10
decade_counts = df.groupby('decade').size()
```

