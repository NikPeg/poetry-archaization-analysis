# Скрипты обработки и анализа данных

Все скрипты проекта организованы по этапам исследования согласно плану в основном README.

---

## Этап 1: Подготовка данных

### `parse_xml_to_csv.py`
**Назначение:** Парсинг XML датасета и конвертация в CSV/Parquet форматы.

**Использование:**
```bash
python src/parse_xml_to_csv.py
```

**Что делает:**
- Парсит `dataset/all.xml`
- Извлекает все поля стихотворений (author, name, text, dates, themes)
- Вычисляет средний год написания (`year`)
- Сохраняет результат в:
  - `dataset/poems.csv` - человекочитаемый формат (24 MB)
  - `dataset/poems.parquet` - оптимизированный формат (13 MB, экономия 45%)
- Выводит статистику по датасету

**Результат:**
- 16,694 стихотворений
- 195 авторов
- Период: 1725-1996
- 77% стихотворений имеют даты

### `example_load_data.py`
**Назначение:** Примеры загрузки и базовой работы с датасетом.

**Использование:**
```bash
python src/example_load_data.py
```

**Что показывает:**
- Как загрузить данные из CSV или Parquet
- Фильтрация по автору и периоду
- Базовая статистика
- Примеры анализа

---

## Этап 2: Формирование словаря архаизмов

### `parse_archaisms.py`
**Назначение:** Парсинг словаря устаревших слов из текстового файла.

**Использование:**
```bash
python src/parse_archaisms.py
```

**Что делает:**
- Парсит `dataset/устаревшие.txt` (источник: azbyka.ru)
- Извлекает слова, определения и варианты написания
- Сохраняет результат в:
  - `dataset/archaisms.csv` - полный словарь с определениями (124 KB)
  - `dataset/archaisms.parquet` - оптимизированный формат (78 KB)
  - `dataset/archaisms_wordlist.txt` - простой список слов для поиска (17 KB)
- Выводит статистику по словарю

**Результат:**
- 1,123 словарных записи
- 1,188 уникальных слов (с вариантами)
- Распределение по алфавиту

### `example_find_archaisms.py`
**Назначение:** Примеры поиска архаизмов в стихотворениях.

**Использование:**
```bash
python src/example_find_archaisms.py
```

**Что показывает:**
- Как загрузить словарь архаизмов
- Поиск архаизмов в текстах
- Подсчёт процента архаизмов
- Сравнение разных авторов и эпох

---

## Этап 3: Анализ частотности

### `word_frequency_analysis.py`
**Назначение:** Анализ частотности слов по векам с визуализацией.

**Использование:**
```bash
python src/word_frequency_analysis.py
```

**Что делает:**
- Разделяет корпус по векам (18, 19, 20)
- Подсчитывает частотность всех слов
- Создаёт облака слов двух типов для каждого века:
  - **Частые слова** - чем чаще, тем крупнее
  - **Редкие слова** - чем реже, тем крупнее (инвертированное)
- Сохраняет визуализации в `results/`

**Результат:**
6 PNG-изображений (по 2 для каждого века):
- `wordcloud_18_century_frequent.png` и `*_rare.png`
- `wordcloud_19_century_frequent.png` и `*_rare.png`
- `wordcloud_20_century_frequent.png` и `*_rare.png`

**Статистика по векам:**
- 18 век: 375 стихотворений, 21,463 уникальных слова
- 19 век: 4,684 стихотворения, 74,171 уникальное слово
- 20 век: 7,798 стихотворений, 124,371 уникальное слово

---

## Структура данных

После парсинга датасет имеет следующие колонки:

| Колонка    | Тип    | Описание                                    | Пример                    |
|------------|--------|---------------------------------------------|---------------------------|
| author     | str    | Имя автора                                  | "Александр Пушкин"        |
| name       | str    | Название стихотворения                      | "Я помню чудное мгновенье"|
| text       | str    | Полный текст стихотворения                  | "Я помню чудное..."       |
| date_from  | str    | Год начала написания (может быть пустым)    | "1825"                    |
| date_to    | str    | Год окончания написания (может быть пустым) | "1825"                    |
| themes     | str    | Темы через запятую (может быть пустым)      | "О любви, Романтизм"      |
| year       | float  | Средний год написания для анализа           | 1825.0                    |

---

## Быстрый старт

### 1. Активация виртуального окружения
```bash
source venv/bin/activate
```

### 2. Загрузка данных в Python
```python
import pandas as pd

# Быстрая загрузка (рекомендуется)
df = pd.read_parquet('dataset/poems.parquet')

# Или из CSV
df = pd.read_csv('dataset/poems.csv')
```

### 3. Базовый анализ
```python
# Фильтрация по автору
pushkin = df[df['author'] == 'Александр Пушкин']

# Фильтрация по периоду
golden_age = df[(df['year'] >= 1820) & (df['year'] < 1840)]

# Группировка по десятилетиям
df['decade'] = (df['year'] // 10) * 10
decade_counts = df.groupby('decade').size()
```

